{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ivul_website.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV5h6ep11mo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Init: bernard { display-mode: \"form\" }\n",
        "#@markdown ```[p['title'] for p in bernard]```\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "json_file = Path('bernard.json')\n",
        "if json_file.exists():\n",
        "    with open(json_file, 'r') as f:\n",
        "        bernard = json.load(f)\n",
        "else:\n",
        "    !pip install -q scholarly\n",
        "    import scholarly\n",
        "\n",
        "    bernard = []\n",
        "    bernard = next(scholarly.search_author('Bernard Ghanem')).fill()\n",
        "    for i, p in enumerate(bernard.publications):\n",
        "        try:\n",
        "            if not p._filled:\n",
        "                p.fill()\n",
        "            p.bib['filled'] = True\n",
        "        except Exception as e:\n",
        "            p.bib['filled'] = False\n",
        "            # print(i, p.bib['title'])\n",
        "            # print(e)\n",
        "        bernard.append(p.bib)\n",
        "    bernard.append({\n",
        "        'title': 'Stroke Style Transfer',\n",
        "        'year': '2017',\n",
        "        'author': 'Sara Shaheen and Bernard Ghanem',\n",
        "        'pages': '53-56',\n",
        "        'filled': True,\n",
        "        'publisher': 'Eurographics Association',\n",
        "    })\n",
        "    with open(json_file, 'w') as f:\n",
        "        json.dump(bernard, f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S50Wbxy2occ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Init: pages { display-mode: \"form\" }\n",
        "#@markdown ```[Parser(p).title for p in pages]```\n",
        "from urllib.request import urlopen\n",
        "\n",
        "\n",
        "ivul_pub_link = 'https://ivul.kaust.edu.sa/Pages/{}.aspx'\n",
        "ivul_pub_list = [\n",
        "    'pat',\n",
        "    'Fluid-Dynamic-Texture',\n",
        "    'pub-cfn',\n",
        "    'pub-multitask-metric-learning',\n",
        "    'pub-deep-gcn',\n",
        "    'pub-pedestrian-detection',\n",
        "    'pub-missing-labels',\n",
        "    'pub-oil',\n",
        "    'pub-unaligned-tiny-faces',\n",
        "    'pub-stochastic-solvers',\n",
        "    'pub-underwater-coloring',\n",
        "    'pub-completion-3d-tracking',\n",
        "    'pub-mining-pesudo-bb',\n",
        "    'pub-vqa-robustness',\n",
        "    'pub-driving-policy-transfer',\n",
        "    'pub-fpv-racer',\n",
        "    'pub-analytic-expressions',\n",
        "    'pub-sim4cv',\n",
        "    'pub-sstad',\n",
        "    'pub-annotate',\n",
        "    'pub-fch',\n",
        "    'pub-lpbox',\n",
        "    'pub-l0tv',\n",
        "    'pub-action-search',\n",
        "    'pub-tiny-faces',\n",
        "    'pub-trackingnet',\n",
        "    'pub-detad',\n",
        "    'pub-sod-mtgan',\n",
        "    'Pub-Phase-PCA-Texture',\n",
        "    'Pub-Manhattan-Frame-Estimation-CVPR-2015',\n",
        "    'pub-w2f',\n",
        "    'pub-soccernet',\n",
        "    'pub-kinectfusion',\n",
        "    'pub-MLML',\n",
        "    'pub-istanet',\n",
        "    'pub-tagging-like-humans',\n",
        "    'pub-csc-drawings',\n",
        "    'pub-3d-detect',\n",
        "    'pub-high-order-csc',\n",
        "    'pub-fft-lasso',\n",
        "    'pub-stroke-style-transfer',\n",
        "    'Pub-Activity-Net',\n",
        "    'pub-sst-action-proposals',\n",
        "    'pub-scc-efficient-action-detection',\n",
        "    'pub-ca-cf-tracking',\n",
        "    'pub-diverse-image-annotation',\n",
        "    'pub-matrix-splitting-method',\n",
        "    'pub-benchmark-simulator-uav',\n",
        "    'pub-circulant-sparse-tracker',\n",
        "    'pub-asset-extraction',\n",
        "    'pub-exact-penalty',\n",
        "    'pub-Daps',\n",
        "    'pub-target-response-adaptation',\n",
        "    'pub-temporal-activity-proposals',\n",
        "    'pub-patternrecognition-2016',\n",
        "    'Pub-Adaptive-Kernelized-Correlation-Filters',\n",
        "    'pub-3d-sparse-tracker',\n",
        "    'Pub-LoTv-Image-Restoration',\n",
        "    'Pub-SAR',\n",
        "    'Pub-ML-MG',\n",
        "    'Pub-Memorable-Object',\n",
        "    'Pub-Scene-Decomposition',\n",
        "    'pub-Constrained-Submodular-Minimization',\n",
        "    'Pub-Proximal-Alternating',\n",
        "    'Pub-BILGO-Large-Scale-Semi-Prog',\n",
        "    'Pub-Auto-Recog-AF-Plays',\n",
        "    'Pub-Real-Time%20Vision-Based',\n",
        "    'Pub-Sparse-Coding',\n",
        "    'Pub-Distance-Learning',\n",
        "    'Pub-Cost-Estimation',\n",
        "    'Pub-Lymph-Reduction',\n",
        "    'Pub-Phase-Based-Modelling-Dynamic-Textures',\n",
        "    'Pub-SPIQA',\n",
        "    'Pub-highlight-estimation-ICPR',\n",
        "    'Pub-Humans-Fixation',\n",
        "    'Pub-Low-Rank',\n",
        "    'Pub-Modeling-dynamic-swarms',\n",
        "    'Pub-Robust-Visual-Tracking-Sparse',\n",
        "    'Pub-Trajectory-Fisher',\n",
        "    'Pub-Obj-Track-Occlusion',\n",
        "    'Pub-Visual-Attributes-CVPR-2015',\n",
        "    'Pub-Camera-Networks',\n",
        "    'Pub-Action-Recog-Traj-Groups',\n",
        "    'Pub-Pose-Estimation',\n",
        "    'Pub-Camer-Motion',\n",
        "    'Pub-Sparse-Tracking',\n",
        "    'Pub-Robust-Tracking',\n",
        "    'Pub-Template-Assembly',\n",
        "    'Pub-Robust-Vis-Track',\n",
        "    'Pub-3D-Aware-Correction',\n",
        "    'Pub-Low-Rank-Sparse-Coding',\n",
        "    'Pub-Topic-Model-Approach-Rep-Class-AFP',\n",
        "    'Pub-Normalized-Cuts',\n",
        "    'Pub-MIS-Boost',\n",
        "    'Pub-Dictionary-Learning',\n",
        "    'Pub-Sparse-Visual-Tracking',\n",
        "    'Pub-Multiobject-Tracking',\n",
        "    'Pub-Video-Registration',\n",
        "    'Pub-Saliency-Models',\n",
        "    'Pub-Visual-Tracking',                \n",
        "]\n",
        "json_file = Path('pages.json')\n",
        "if json_file.exists():\n",
        "    with open(json_file, 'r') as f:\n",
        "        pages = json.load(f)\n",
        "else:\n",
        "    pages = []\n",
        "    for url in ivul_pub_list:\n",
        "        with urlopen(ivul_pub_link.format(url)) as f:\n",
        "            pages.append(f.read().decode('utf8'))\n",
        "    with open(json_file, 'w') as f:\n",
        "        json.dump(pages, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTb_8HuPVUQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Init: publications { display-mode: \"form\" }\n",
        "#@markdown ```list(Match.verify(publications, bernard))```\n",
        "import re\n",
        "from collections import OrderedDict\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "class Parser:\n",
        "    Distinctions = (\n",
        "        'Short Paper', 'Spotlight',\n",
        "        'Oral', 'Best Paper Award',\n",
        "    )\n",
        "    Venues = OrderedDict((\n",
        "        ('PatternRecognition', 'Pattern Recognition Journal'),\n",
        "        ('NeuroComputing', 'Neurocomputing Journal'),\n",
        "        ('EuroGraphics', 'EuroGraphics Computer Graphics Forum'),\n",
        "        ('Cybernetics', 'IEEE Transactions on Cybernetics'),\n",
        "        ('ICASSP', 'IEEE International Conference on Acoustics, Speech and Signal Processing'),\n",
        "        ('TPAMI', 'IEEE Transactions on Pattern Analysis and Machine Intelligence'),\n",
        "        ('CVPRW', 'IEEE Conference on Computer Vision and Pattern Recognition Workshops'),\n",
        "        ('ICCVW', 'IEEE International Conference on Computer Vision Workshops'),\n",
        "        ('ECCVW', 'IEEE European Conference on Computer Vision Workshops'),\n",
        "        ('CVPR', 'IEEE Conference on Computer Vision and Pattern Recognition'),\n",
        "        ('ICCV', 'IEEE International Conference on Computer Vision'),\n",
        "        ('ECCV', 'IEEE European Conference on Computer Vision'),\n",
        "        ('AAAI', 'Association for the Advancement of Artificial Intelligence'),\n",
        "        ('ICLR', 'International Conference on Learning Representations'),\n",
        "        ('BMVC', 'British Machine Vision Conference'),\n",
        "        ('IJCV', 'International Journal of Computer Vision'),\n",
        "        ('ICPR', 'International Conference on Pattern Recognition'),\n",
        "        ('ACCV', 'Asian Conference on Computer Vision'),\n",
        "        ('WACV', 'IEEE Winter Conference on Applications of Computer Vision'),\n",
        "        ('CORL', 'Conference on Robot Learning'),\n",
        "        ('ICIP', 'IEEE International Conference on Image Processing'),\n",
        "        ('IROS', 'International Conference on Intelligent Robots and Systems'),\n",
        "        ('CVIU', 'Computer Vision and Image Understanding'),\n",
        "        ('RSS', 'Robotics Science and Systems'),\n",
        "    ))\n",
        "\n",
        "    def __init__(self, html):\n",
        "        self.soup = BeautifulSoup(html)\n",
        "        self.blocks = {\n",
        "            k: l.find_next_sibling()\n",
        "            # inside <div class=DisplayBlock></div>\n",
        "            for l in self.soup.find_all('label')\n",
        "            for k in [l.get_text().strip()[:-1].lower().split(' ')[-1]]\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def text(element):\n",
        "        string = element.get_text().strip()\n",
        "        string = string.replace('\\xa0', ' ').replace('\\u200b', '')\n",
        "        return string.strip()\n",
        "\n",
        "    @property\n",
        "    def title(self):\n",
        "        element = self.soup.find(id='publication-Details-Title')\n",
        "        return self.text(element).replace('\"', '')\n",
        "\n",
        "    @property\n",
        "    def author(self):\n",
        "        return self.text(self.soup.find(id='kaustAuthors'))\n",
        "\n",
        "    @property\n",
        "    def venue(self):\n",
        "        b = self.bibliography.lower()\n",
        "        for c in self.Venues:\n",
        "            if c.lower() in b:\n",
        "                out = c\n",
        "                break\n",
        "        else:\n",
        "            if 'pattern recognition' in b:\n",
        "                out = 'PatternRecognition'\n",
        "            elif 'computer graphics forum' in b or 'eurographics' in b:\n",
        "                out = 'EuroGraphics'\n",
        "            elif 'cvsports' in b:\n",
        "                out = 'CVPRW'\n",
        "            else:\n",
        "                # raise ValueError(f'could not parse {b}')\n",
        "                out = b\n",
        "        return out\n",
        "\n",
        "    @property\n",
        "    def year(self):\n",
        "        element = self.soup.find(id='publication-Year')\n",
        "        element = element.find(attrs={'class': 'publication-body'})\n",
        "        return int(self.text(element))\n",
        "\n",
        "    @property\n",
        "    def distinction(self):\n",
        "        out = []\n",
        "        for r in re.findall('(\\[.*\\]|\\(.*\\))', self.bibliography):\n",
        "            r = r.lower()\n",
        "            for d in self.Distinctions:\n",
        "                if d.lower() in r:\n",
        "                    out.append(d)\n",
        "        text = str(self.blocks.get('information', ''))\n",
        "        if 'spotlight' in text.lower():\n",
        "            out.append('Spotlight')\n",
        "        return out\n",
        "\n",
        "    @property\n",
        "    def abstract(self):\n",
        "        text = self.text(self.blocks['abstract'])[8:]\n",
        "        return text.replace('\\n', ' ').replace('  ', ' ').strip()\n",
        "\n",
        "    @property\n",
        "    def keyword(self):\n",
        "        text = self.text(self.soup.find(id='publicationKeywords'))\n",
        "        return [k.strip().lower() for k in text.split(',')]\n",
        "\n",
        "    @property\n",
        "    def bibliography(self):\n",
        "        return self.text(self.blocks['bibliography'])\n",
        "\n",
        "    @property\n",
        "    def pdf(self):\n",
        "        return self.soup.find(id='docLink').find('a').attrs['href']\n",
        "\n",
        "    @property\n",
        "    def website(self):\n",
        "        return self.soup.find(id='webLink').find('a').attrs['href']\n",
        "\n",
        "    @property\n",
        "    def link(self):\n",
        "        element = self.blocks.get('information')\n",
        "        if element is None:\n",
        "            out = {}\n",
        "        else:\n",
        "            out = {self.text(a).lower(): a.attrs['href']\n",
        "                    for a in element.find_all('a')}\n",
        "        if self.pdf:\n",
        "            out['paper'] = self.pdf\n",
        "        if self.website:\n",
        "            out['website'] = self.website\n",
        "        for k in ('', ']', '[', 'suppl 1', 'suppl 2'):\n",
        "            if k in out:\n",
        "                del out[k]\n",
        "        for k in tuple(out):\n",
        "            if 'suppl' in k:\n",
        "                out['supplementary'] = out.pop(k)\n",
        "            elif 'bibt' in k:\n",
        "                out['bibtex'] = out.pop(k)\n",
        "            elif 'data' in k:\n",
        "                out['data'] = out.pop(k)\n",
        "            elif any(s in k for s in (\n",
        "                'simulator', 'project', 'derivation')):\n",
        "                out.pop(k)\n",
        "            elif k[0] == '[' and k[-1] == ']':\n",
        "                out[k[1:-1]] = out.pop(k)\n",
        "        return out\n",
        "\n",
        "    def __iter__(self):\n",
        "        keys = ('title', 'author', 'venue', 'year', 'keyword',\n",
        "                'distinction', 'link', 'bibliography', 'abstract')\n",
        "        for k in keys:\n",
        "            yield k, getattr(self, k)\n",
        "\n",
        "class Match:\n",
        "    @staticmethod\n",
        "    def count(s):\n",
        "        out = {}\n",
        "        for c in s:\n",
        "            if c not in out:\n",
        "                out[c] = 0\n",
        "            out[c] += 1\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def intersection(s_count, z_count):\n",
        "        out = {}\n",
        "        for k in s_count:\n",
        "            if k in z_count:\n",
        "                out[k] = min(s_count[k], z_count[k])\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def union(s_count, z_count):\n",
        "        out = {}\n",
        "        for k in set(s_count).union(z_count):\n",
        "            out[k] = max(s_count.get(k, 0), z_count.get(k, 0))\n",
        "        return out\n",
        "\n",
        "    @classmethod\n",
        "    def distance(cls, s, z):\n",
        "        if s == z:\n",
        "            return 0\n",
        "        s_count = cls.count(s.strip().lower())\n",
        "        z_count = cls.count(z.strip().lower())\n",
        "        union = cls.union(s_count, z_count)\n",
        "        intersection = cls.intersection(s_count, z_count)\n",
        "        total = sum([intersection.get(k, 0) / union[k] for k in union])\n",
        "        return 1 - total / len(union)\n",
        "\n",
        "    @classmethod\n",
        "    def closest(cls, title, data, key=lambda x: x['title']):\n",
        "        distances = (cls.distance(key(e), title) for e in data)\n",
        "        index, value = min(enumerate(distances), key=lambda x: x[1])\n",
        "        return index, value\n",
        "\n",
        "    @classmethod\n",
        "    def verify(cls, queries, data, threshold=0, key=lambda x: x['title']):\n",
        "        for i, q in enumerate(queries):\n",
        "            j, v = cls.closest(key(q), data)\n",
        "            if v > threshold:\n",
        "                yield {\n",
        "                    'index': i,\n",
        "                    'found': j,\n",
        "                    'query': key(q),\n",
        "                    'match': key(data[j]),\n",
        "                    'value': v,\n",
        "                }\n",
        "\n",
        "json_file = Path('publications.json')\n",
        "if json_file.exists():\n",
        "    with open(json_file, 'r') as f:\n",
        "        publications = json.load(f)\n",
        "else:\n",
        "    publications = [dict(Parser(p)) for p in pages]\n",
        "    for p in publications:\n",
        "        index = Match.closest(p['title'], bernard)[0]\n",
        "        p['scholar'] = bernard[index]\n",
        "    with open(json_file, 'w') as f:\n",
        "        json.dump(publications, f)\n",
        "\n",
        "pages = [p for i, p in enumerate(pages) if publications[i]['year'] >= 2012]\n",
        "publications = [p for p in publications if p['year'] >= 2012]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-rv3NZdzxX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Init: biblib { display-mode: \"form\" }\n",
        "#@markdown ```[b.venue for b in biblib]```\n",
        "import pickle\n",
        "from typing import Tuple\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class BibTex:\n",
        "    title: str\n",
        "    authors: Tuple[str, ...]\n",
        "    coauthors: Tuple[bool, ...]\n",
        "    venue: str\n",
        "    year: int\n",
        "    abstract: str\n",
        "    distinctions: Tuple[str, ...]\n",
        "    keywords: Tuple[str, ...]\n",
        "    links: Tuple[Tuple[str, str], ...]\n",
        "\n",
        "    def __init__(self, p):\n",
        "        self.title = str(p['title'])\n",
        "        self.authors = self.parse_authors(p['scholar']['author'])\n",
        "        self.coauthors = self.parse_coauthors(p['bibliography'],\n",
        "                                              len(self.authors))\n",
        "        self.venue = str(p['venue'])\n",
        "        self.year = int(p['year'])\n",
        "        self.abstract = str(p['abstract'])\n",
        "        self.distinctions = tuple(p['distinction'])\n",
        "        self.keywords = tuple(p['keyword'])\n",
        "        self.links = tuple((k, v) for k, v in p['link'].items())\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_authors(authors):\n",
        "        fix = OrderedDict((\n",
        "            ('Peter Wonka', ['Peter Wonka Liangliang Nan']),\n",
        "            ('Liangliang Nan', ['Peter Wonka Liangliang Nan']),\n",
        "            ('Vladlen Koltun', ['Vladen Koltun']),\n",
        "            ('Matthias Müller', ['Matthias Mueller', 'Matthias Muller']),\n",
        "            ('Bernard Ghanem', ['Bernard Ghanem Ghanem',\n",
        "                                'Bernard S Ghanem']),\n",
        "            ('Ali Thabet', ['Ali K Thabet']),\n",
        "        ))\n",
        "        out = []\n",
        "        for a in authors.split(' and '):\n",
        "            found = False\n",
        "            for k, v in fix.items():\n",
        "                if a in v:\n",
        "                    out.append(k)\n",
        "                    found = True\n",
        "            if not found:\n",
        "                out.append(str(a))\n",
        "        return tuple(out)\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_coauthors(bib, num_authors):\n",
        "        s = [x for y in bib.split(',') for x in y.split('and')]\n",
        "        return tuple(x.strip().endswith('*')\n",
        "                     for x in s[:num_authors - 1] + [''])\n",
        "\n",
        "    @property\n",
        "    def full_venue(self):\n",
        "        return Parser.Venues[self.venue]\n",
        "\n",
        "    @property\n",
        "    def reference(self):\n",
        "        title = (w[:1] for w in self.title.split(' '))\n",
        "        title = ''.join(c.upper() for c in title if c.isalpha())\n",
        "        name = self.authors[0].split(' ')[-1]\n",
        "        name = name.replace('é', 'e').replace('ł', 'l').replace('ü', 'u')\n",
        "        return f'{name}_{self.year}_{self.venue}_{title[:5]}'\n",
        "\n",
        "    @property\n",
        "    def bib(self):\n",
        "        return ',\\n  '.join([\n",
        "            '@InProceedings{' + self.reference,\n",
        "            'title = {' + self.title + '}',\n",
        "            'booktitle = {' + self.full_venue + f' ({self.venue})}}',\n",
        "            # 'month = {' + self.month + '}',\n",
        "            'year = {' + str(self.year) + '}',\n",
        "        ]) + ',\\n}'\n",
        "\n",
        "pickle_file = Path('biblib.pkl')\n",
        "if pickle_file.exists():\n",
        "    with open(pickle_file, 'rb') as f:\n",
        "        biblib = pickle.load(f)\n",
        "else:\n",
        "    biblib = [BibTex(p) for p in publications]\n",
        "    with open(pickle_file, 'wb') as f:\n",
        "        pickle.dump(biblib, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIHgU5Vegq5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Init: Tag and plain_html { display-mode: \"form\" }\n",
        "#@markdown ```\n",
        "#@markdown with open('0.html', 'w') as f:\n",
        "#@markdown     f.write(str(plain_html(biblib)))\n",
        "#@markdown ```\n",
        "class Tag:\n",
        "    VoidElements = {\n",
        "        'area', 'img', 'base', 'br', 'col', 'command', 'embed', 'track'\n",
        "        'hr', 'input', 'keygen', 'link', 'meta', 'param', 'source', 'wbr',\n",
        "    }\n",
        "    def __init__(self, name, *children, **attrs):\n",
        "        self.name = name.lower()\n",
        "        if 'klass' in attrs:\n",
        "            attrs['class'] = attrs.pop('klass')\n",
        "        self.attrs = attrs\n",
        "        if self.name in self.VoidElements:\n",
        "            assert not children\n",
        "        else:\n",
        "            self.children = list(children)\n",
        "\n",
        "    def __getitem__(self, tags):\n",
        "        if not isinstance(tags, tuple):\n",
        "            tags = (tags,)\n",
        "        for tag in tags:\n",
        "            self.children.append(tag)\n",
        "        return self\n",
        "\n",
        "    def __repr__(self):\n",
        "        attrs = ' '.join(f'{k}=\"{v}\"' for k, v in self.attrs.items())\n",
        "        sep = ' ' if attrs else ''\n",
        "        out = f'<{self.name}{sep}{attrs}>'\n",
        "        if hasattr(self, 'children'):\n",
        "            children = ''.join(str(c) for c in self.children)\n",
        "            out += f'{children}</{self.name}>'\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def encode(string):\n",
        "        return string.encode('ascii', 'xmlcharrefreplace').decode('utf-8')\n",
        "\n",
        "def plain_html(biblib):\n",
        "    html = Tag('html')[Tag('head'), Tag('body')]\n",
        "    for i, b in enumerate(biblib):\n",
        "        html.children[-1][Tag('div')[\n",
        "            # title\n",
        "            Tag('h3')[str(i), ' ', b.title],\n",
        "            # authors\n",
        "            Tag('p')[', '.join(\n",
        "                Tag.encode(a + c) for a, s in zip(b.authors, b.coauthors)\n",
        "                for c in ['*' if s else '']\n",
        "            )],\n",
        "            # venue (year) [distinction1] [distinction2]\n",
        "            Tag('p')[\n",
        "                'In <i>The ',\n",
        "                b.full_venue,\n",
        "                '</i>',\n",
        "                ' ({} {}) '.format(b.venue, b.year),\n",
        "                ' '.join(f'[{d}]' for d in  b.distinctions),\n",
        "            ],\n",
        "            # abstract\n",
        "            Tag('p')[Tag.encode(b.abstract)],\n",
        "            # Keywords: keyword1, keyword2\n",
        "            Tag('p')[\n",
        "                Tag('b')['Keywords: '], \n",
        "                ', '.join(Tag.encode(k) for k in b.keywords)\n",
        "            ],\n",
        "            # Links: [link1][link2]\n",
        "            Tag('p')[(Tag('b')['Links: '],) + tuple(\n",
        "                Tag('a', href=href)['[{}]'.format(text)]\n",
        "                for text, href in b.links\n",
        "            )],\n",
        "        ]]\n",
        "    return html\n",
        "\n",
        "# <!-- Embed --!>\n",
        "# <div class=\"embed-responsive embed-responsive-1by1\">\n",
        "#   <iframe class=\"embed-responsive-item\" id=\"main-iframe\"></iframe>\n",
        "#   <script language=\"javascript\" type=\"text/javascript\">\n",
        "#     const p = \"https://ivul-kaust.github.io/\" + window.location.search;\n",
        "#     document.getElementById(\"main-iframe\").src = p;\n",
        "#   </script>\n",
        "# </div>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrQHsbxI7rpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Generate PDF previews { display-mode: \"form\" }\n",
        "#@markdown ```preview('paper.pdf', height=512).show()```\n",
        "from pathlib import Path\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def load_page(pdf, number, height):\n",
        "    from preview_generator.manager import PreviewManager\n",
        "    with TemporaryDirectory() as cache:\n",
        "        manager = PreviewManager(cache)\n",
        "        page = number - 1\n",
        "        pdf = str(Path(pdf).absolute())\n",
        "        path = manager.get_jpeg_preview(pdf, page=page, height=height)\n",
        "        return Image.open(path)\n",
        "\n",
        "def preview(pdf, height=512, aspect_ratio=16 / 9):\n",
        "    page1 = load_page(pdf, 1, height)\n",
        "    page2 = load_page(pdf, 2, height)\n",
        "    array = np.concatenate((page1, page2), axis=1)\n",
        "    width = int(round(height * aspect_ratio))\n",
        "    padding = width - array.shape[1]\n",
        "    left = abs(padding) // 2\n",
        "    right = left + padding % 2\n",
        "    if padding < 0:\n",
        "        array = array[:, left:-right, ...]\n",
        "    else:\n",
        "        shape = (height, right) + array.shape[2:]\n",
        "        pad = np.zeros(shape, dtype=array.dtype) + array.max()\n",
        "        s = None if left == right else -1\n",
        "        array = np.concatenate((pad[:, :s, ...], array, pad), axis=1)\n",
        "    return Image.fromarray(array)\n",
        "\n",
        "paper_folder = Path('paper')\n",
        "if paper_folder.exists():\n",
        "    for folder in paper_folder.iterdir():\n",
        "        jpg = folder / (folder.name + '.jpg')\n",
        "        if jpg.exists():\n",
        "            continue\n",
        "        pdf = folder / (folder.name + '.pdf')\n",
        "        img = preview(pdf, 512)\n",
        "        img.thumbnail((455, 256), Image.ANTIALIAS)\n",
        "        img.save(jpg, \"JPEG\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8GJoBOodCQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Init: thumbnail, paper, and theme { display-mode: \"form\" }\n",
        "# // script.google.com\n",
        "# function listDriveFolder() {\n",
        "#   var folder = DriveApp.getFolderById('1tyFWt6v9vrXhs4OR9Jhfo76F3wtWGLOG');\n",
        "#   var sheet = SpreadsheetApp.create(folder.getName()).getActiveSheet();  \n",
        "#   var publications = folder.getFolders();\n",
        "#   while(publications.hasNext()){\n",
        "#     var publication = publications.next().getFiles();\n",
        "#     while(publication.hasNext()){\n",
        "#       var file = publication.next();\n",
        "#       file.setSharing(DriveApp.Access.ANYONE_WITH_LINK, DriveApp.Permission.VIEW);\n",
        "#       sheet.appendRow([file.getName(), file.getUrl()]);\n",
        "#     }\n",
        "#   }\n",
        "# }\n",
        "\n",
        "# the sharable urls have to be put in this format:\n",
        "# https://drive.google.com/a/kaust.edu.sa/thumbnail?id={imageID}\n",
        "thumbnail = {\n",
        "    'Muller_2018_ECCV_TALDA': '1FUGH7yQy9PzBXPM61Fw_LI3RfikkM4EV',\n",
        "    'Muller_2016_IROS_PATSF': '1vsPALrtV2ZElDeG5wPmKQlKlkZZ8kBKO',\n",
        "    'Muller_2018_IJCV_SAPSF': '1JRiGrhw3rNKL47HFLHiCYrd65WwWt0Rr',\n",
        "    'Muller_2018_ECCVW_TUTRE': '1spLy_koUIHmeQAhKu0UhV7t9g8AAuiGo',\n",
        "    'Muller_2017_CVPR_CCFT': '1BQNfvagp6RcDkNxvrGlcR_XgZWAhjyso',\n",
        "    'Muller_2018_CORL_DPTVM': '1U7pfMeYF2QOkvLislulPRk15L3HnU_Bv',\n",
        "    'Li_2019_ICCV_CGGAD': '1dBsem8ufxELFXHFnKj42cp8uUjg1iOS5',\n",
        "    'Li_2019_RSS_OOIL': '1mWx7nbh8g2cL6pn20k9vD0tfq9h1WCwW',\n",
        "    'Muller_2016_ECCV_ABASF': '1GeX5Jkxi9oGnlWvVCL3B3WAfu5k3ZqJi',\n",
        "    'Heilbron_2018_ECCV_WDIAN': '1nu192a-faDxdlrg0EU7_WQREOheLq_XI',\n",
        "    'Li_2016_PatternRecognition_FAURU': '1AM6alAuWtv7kzkxyxfLRP8vGW3QdgXt2',\n",
        "    'Lahoud_2019_ICCV_ISVMM': '1oO2I62BMAxJ8aQXDCwYWO1zPKwJVIcJJ',\n",
        "    'Lahoud_2017_ICCV_ODIRI': '1eVzwfVf15cDH7ClQub_TDiV2guUURAqQ',\n",
        "    'Heili_2014_ACCV_IHABP': '17zqG6Va-QoiPRQfobydlHUFGBncGyOvm',\n",
        "    'Huang_2019_AAAI_ANFFR': '1iTL6OWRgLhxruqKfozpxB7EX4Db3PtLv',\n",
        "    'Heilbron_2014_ACCV_CMASS': '1WR_YeQkYtO06gHu7k9LUcDvEOF4JdN2v',\n",
        "    'Heilbron_2016_CVPR_FTAPF': '19ZGZ_GyKAuw8XFWFZZwZQsUrLbKe2NvP',\n",
        "    'Heilbron_2015_CVPR_AALVB': '1PUSxHYFdHLdwQbtnpCDRUFN5xVWUuMAx',\n",
        "    'Heilbron_2017_CVPR_SSCCF': '15-pBfBp20MKmlOIV4eJZltusjBMUgK2B',\n",
        "    'Giancola_2018_CVPRW_SASDF': '1WaMpmypgTBU7VgXHpu2nypB289mhaGho',\n",
        "    'Ghanem_2012_CVIU_MDS': '1dMK-4NEeaORio9GtxGxqZfye0yV93_be',\n",
        "    'Ghanem_2015_EuroGraphics_DCNBC': '14UzxogR3V8qLksmUY7lg3_akXGOksr01',\n",
        "    'Giancola_2018_CVPRW_IOAOM': '1TrHZhzWBy5cH-jYYwJ1ig_ZIKoIMfOnh',\n",
        "    'Giancola_2019_CVPR_LSCFS': '179WogDvo3OglftnBVCD4t72dRzqEKDDf',\n",
        "    'Ghanem_2012_ICASSP_RVRAT': '1GiHMRifw0k9X1-2doFlE_3_SC5LMKkBY',\n",
        "    'Ghanem_2012_ICPR_CLFAS': '19YxaTQca7x_cmTT2n_jEZsHdOSPtxwpn',\n",
        "    'Hachama_2015_ICCV_ISDFR': '190eJi8LIwR4eXe3Gm8srZBLtJS2NkEBu',\n",
        "    'Ghanem_2015_CVPR_RMFEF': '1Cp4GABrmisjYqbz16HXQ8doWEcpxksG8',\n",
        "    'Dave_2012_ICPR_DHFOI': '1qHb2K-ABSRaIfRj9mVgV5P3qvBaoqjGN',\n",
        "    'Bibi_2019_ICLR_DLASS': '1WtVenF9RmTjXqkvYVY3lh3s6_be80ACq',\n",
        "    'Bibi_2017_ICCV_HOTFF': '1df5PsY2e3Fl5-4jGNOyzAasj7FMut5mc',\n",
        "    'Dubey_2015_ICCV_WMAOM': '1kZY3LJZCNKDo4tbhjZn4nXk0NEuHxe6K',\n",
        "    'Dubey_2014_ACCV_ISMBP': '1whzdguQApivG5EdMHhnmJwtm_MFP4SKQ',\n",
        "    'Buch_2017_BMVC_ESTAD': '1iM5eoOY_VCiXC83kT5Ume6A2wx1ngzEK',\n",
        "    'Bibi_2018_CVPR_AEFPM': '1ebjRvif9ybFgshW0QcTDH8v_XUx9bxOz',\n",
        "    'Escorcia_2015_CVPR_OTRBV': '1qtqoI5MoANTVmB6gtqOw4Ab4U8fMQJ26',\n",
        "    'Buch_2017_CVPR_SSTAP': '1AhIuJqmOnhzxzmh_1S2uBt6QYJiA5V28',\n",
        "    'Escorcia_2016_ECCV_DDAPF': '1OWPmF7naJbQYt6F95xJ8DadLXuSKf4dN',\n",
        "    'Bibi_2015_ICCVW_MSKCF': '1-Pf3XnvcI1ujVp-YUZTCUynGbsM-sNW-',\n",
        "    'Atmosukarto_2015_WACV_ARUDS': '1vUo1BvycNbN_xlrzz8Yuqk_6MNUBETjI',\n",
        "    'Alwassel_2018_ECCV_DEITA': '1uT-7-jWMbujIV7nKeERegpH5toXX8Gpv',\n",
        "    'Bibi_2016_CVPR_PSTWA': '1bQW2I4a1K5csV26rFGaiQQUtWfV175n8',\n",
        "    'Bai_2018_CVPR_FTFIT': '13N6jcV6UKEJMATFSF2RotZJ-Ha5Wc0hL',\n",
        "    'Atmosukarto_2013_CVPRW_AROOT': '1ZGpL7wU5Z6F4xljlWM6qLtaRtsWKU7Vg',\n",
        "    'Bai_2018_ECCV_SSODV': '1aBEMhMZSNi883sWs58sbzG4B6Tm-4MMY',\n",
        "    'Bibi_2017_CVPR_FLLIT': '1YN7RDl6BAPAI15JIXitxue-oczxI11nN',\n",
        "    'Atmosukarto_2012_ICPR_TFKRF': '1IJFBtpTfwq3D41MfnNa_mDH-nU-pMfU5',\n",
        "    'Bibi_2016_ECCV_TRAFC': '1Qbi9IZ-VdhZFWltZ4f33sJPYj7HOP8Jf',\n",
        "    'Zhang_2018_CVPR_WAWTF': '1YTn8NZdL-sKpyPOhyrqhBHQEg7g2jBTv',\n",
        "    'Zhang_2018_PatternRecognition_WODVM': '1kQEIbNdHDR4DkC_ARgtmGZtfdiSW9-Zm',\n",
        "    'Zhang_2013_IJCV_RVTVS': '1O3KDJmXRVkfYz5VUrkW-b3I1-nZ8oqbg',\n",
        "    'Zhang_2015_Cybernetics_RVTVE': '11KjEP99o589F4AQitv01t5KymBSzRuc4',\n",
        "    'Zhang_2014_IJCV_RVTVC': '1K_J2S3r4O9CzHGin_L8cuEK0aLaBvwpJ',\n",
        "    'Zhang_2015_CVPR_SST': '1HZgjm7BCRIa4K33nkKWsBZYsmeNAje_G',\n",
        "    'Zhang_2016_CVPR_IDOST': '17Dw3M6IfIiJHgV18pjOgjpJcXzu9EelB',\n",
        "    'Alwassel_2018_ECCV_ASSAI': '1lHyJ7o3gwYpAKisdlHq9ZTngoypwAUfK',\n",
        "    'Zhang_2018_CVPR_IIODN': '1psm5UEWQz64cvaI0H3JKu1O7bgnuMc1D',\n",
        "    'Affara_2016_ECCV_LSAEF': '1ZjNEga2pArQ3tmLyIqUJuobW4rcJv4bg',\n",
        "    'Zhang_2012_CVPR_RVTVM': '1U9WLbY1uP4laarG4apAlBTW7k6OAjYz2',\n",
        "    'Yuan_2017_TPAMI_LASOM': '1Eeww9huQkF5iGZpfbPTviMN-jGLsSHTv',\n",
        "    'Zhang_2012_ECCV_LSLFR': '1nWCT84Qtw1YW4UY3pnARfas6RL7ZohrW',\n",
        "    'Zhang_2013_ICCV_LSCFI': '1jTzAQZ6UHi-wnfNNVmqpFYW6TjWxbl-X',\n",
        "    'Zhang_2013_CVPRW_OTBOD': '1HLfBLdsu1RBSewAB1ab5D1xQhck5ADwl',\n",
        "    'Yuan_2017_AAAI_AEPMF': '1L4YOoCba_hvXCbWh3vo1eZnHaEIAdEqY',\n",
        "    'Yuan_2016_AAAI_APADM': '1Vr-UfsjicGxbR3t95EGZ9GEa4KPa-nHA',\n",
        "    'Yuan_2015_CVPR_LANMF': '1RV4EKdO2wXMRNkD1_ZIng7ZWb0jg0EBy',\n",
        "    'Zhang_2012_ICASSP_RMTVC': '1lqshI5YYIrpkejiczVQioxOPFB5_z5Aw',\n",
        "    'Yuan_2017_CVPR_AMSMF': '1aAQpe-hke8St5-ZuQ9hhUp5AwdFYfdiq',\n",
        "    'Xu_2019_CVPRW_MLIOD': '1X6kxlLO1dTq0TcgmRi7pEeaTUAhMNeuq',\n",
        "    'Yu_2018_ECCV_FSGBF': '1Hw2mmgajfHnZyzf48SIrX-sfjIskWT30',\n",
        "    'Xu_2019_CVPRW_SPRFR': '1_V_VGo5jFzJbjXRPfHKcseV99O5-1-u0',\n",
        "    'Wu_2018_TPAMI_LAAVF': '1h2Snnstq3-BYS-9DakjpZP4lNcn_ANro',\n",
        "    'Yu_2019_TPAMI_CWSMJ': '1U95Ix4mSaGouumQntgZQUP2CsQ8_iLi5',\n",
        "    'Wu_2017_CVPR_DIA': '18CEb_ZBCgcwlN96bVgUJ4k2Kzqns6afr',\n",
        "    'Wu_2018_CVPR_TLHDA': '12o_qho7H3ijEb8sPEfDQxOVxPNt4c48h',\n",
        "    'Yuan_2013_NeuroComputing_BBGOF': '1vbBjTCtPm5Quprr181psaJgL1Y2VOsXr',\n",
        "    'Yuan_2012_NeuroComputing_LQSP': '1aaM8RXk9US-MQoG3PVAJF7SI2lCP1sIa',\n",
        "    'Wu_2018_IJCV_MLWML': '1sSX4zZw6W0Rk-t2JGXPhRcOTaniM8lfW',\n",
        "    'Shaheen_2017_EuroGraphics_SST': '1uaTZHL9ukbwnVEXUW9_9XwJEkTQ83drf',\n",
        "    'Muller_2019_CVPRW_LACFN': '1Gl_iVDaOdUglHXBjIaXS3Pv2op6XXwQt',\n",
        "    'Thabet_2014_ACCV_ACACO': '1sNVnIqs7YW4Wpdogb110LQ5Rcd2uvIH5',\n",
        "    'Shaheen_2015_EuroGraphics_SSAR': '1fs6t6mP9puVpujbKPGWHpVC87oqVzIpp',\n",
        "    'Wu_2015_ICCV_MMLWM': '1_EUnXXFEfoD7H5xznWgiWTUYDXgLWRGH',\n",
        "    'Shaheen_2017_ICCV_CCSCF': '1zL0cWJYibp9h4J19dQQmDbFxmzBrxzIb',\n",
        "    'Wonka_2015_EuroGraphics_TAFDU': '19tG2wvZkLk76CLHe8bQg1zs3yHFj8FfE',\n",
        "    'Varadarajan_2013_BMVC_ATMAT': '1IiFYXiUcH-wsZfBzGwvLwnNc8PF9SlD9',\n",
        "    'Protasiuk_2019_WACV_LCMCW': '1GoZ89Co5Dbl6BU0z4lDvpcnwNkAqZrQ6',\n",
        "    'Wu_2016_AAAI_CSMFM': '1EcYIb1Zh_fjTDI6bh3oc4YYfaC2kGDgN',\n",
        "}\n",
        "# the sharable urls have to be put in this format:\n",
        "# https://drive.google.com/a/kaust.edu.sa/file/d/{fileID}/view?usp=drivesdk\n",
        "paper = {\n",
        "    'Muller_2018_ECCV_TALDA': '1aqPVbSdIp61TGqEveGgQ01jBxR0CnKTc',\n",
        "    'Muller_2016_IROS_PATSF': '1R4KtSVjQee8t8FqdnVr_6aK1SA4P4kBQ',\n",
        "    'Muller_2018_IJCV_SAPSF': '1KnpnunwyB_tmxONnqlmOANjvYsHB-Lul',\n",
        "    'Muller_2018_ECCVW_TUTRE': '1LWrQY-OXg3l3FTTS-FvXIvGswystU0DA',\n",
        "    'Muller_2017_CVPR_CCFT': '1SS-y8wYoT7Nr2LfypCRaco--IAOd5ZTU',\n",
        "    'Muller_2018_CORL_DPTVM': '1Hz_vll5chebyjvB8mdjErW3wXdyBhUj3',\n",
        "    'Li_2019_ICCV_CGGAD': '1nvU-btKvFktIba0dY2Dkk2HNpNxvlvUk',\n",
        "    'Li_2019_RSS_OOIL': '1q9v0_8Ak-_JtqMwVxsu2-gXKMFw8Wfyq',\n",
        "    'Muller_2016_ECCV_ABASF': '1YDlCOWxH8HMPlmblJ2OvxFdSFecuiM3Z',\n",
        "    'Heilbron_2018_ECCV_WDIAN': '1nyotw_mLa-AmiXLL40Npb9e8zTY8qVH2',\n",
        "    'Li_2016_PatternRecognition_FAURU': '1CL7DkhialcpK-lQ64AZ24DbUAqICXw1D',\n",
        "    'Lahoud_2019_ICCV_ISVMM': '1Rh8-TS_vRNo5ZxU78NddH-VaXE-5Znov',\n",
        "    'Lahoud_2017_ICCV_ODIRI': '1BLXqeniZ3Jp8ODoqRg07x76kqOmTlS9V',\n",
        "    'Heili_2014_ACCV_IHABP': '1P5NsvzYHEYHnhCILnQ8tyt_dWedNEz0B',\n",
        "    'Huang_2019_AAAI_ANFFR': '1a_Iizys9IYW1gC6aeQTjeBK75VTb2e8d',\n",
        "    'Heilbron_2014_ACCV_CMASS': '1sihKksW5opuFAINS2-7K2LBBia0Gb08f',\n",
        "    'Heilbron_2016_CVPR_FTAPF': '1DUgPNkvgpLpyG0zlv1pOnIkgivdt9nKL',\n",
        "    'Heilbron_2015_CVPR_AALVB': '14ZYbhAldrL-bWpV7Y7J36eyL5sXmvVnk',\n",
        "    'Heilbron_2017_CVPR_SSCCF': '1dET2PZbiqaXFPncX_qIFIF15boyeKkae',\n",
        "    'Giancola_2018_CVPRW_SASDF': '1RkNnTRlf4m4XyLqD6pIm3xR08k0ndLZA',\n",
        "    'Ghanem_2012_CVIU_MDS': '1C3zQIz5vcIolThs_yGtB4UCDulYG_hmH',\n",
        "    'Ghanem_2015_EuroGraphics_DCNBC': '1vPATbgaTSp1h4LyNEmLXgHZdbPaLUWTX',\n",
        "    'Giancola_2018_CVPRW_IOAOM': '1mg07T9nDc74H5EUuUcqzpEoK8OnKY9AA',\n",
        "    'Giancola_2019_CVPR_LSCFS': '1Yoe7ggGY8NC6G6H3qf6pVDszMeQ4-FlV',\n",
        "    'Ghanem_2012_ICASSP_RVRAT': '1_6j4CGoJrzWhY6rRRrB27yqXPf3VUtc7',\n",
        "    'Ghanem_2012_ICPR_CLFAS': '1rrojnprXHBJ56dxud-T4ZomjcOezwo4U',\n",
        "    'Hachama_2015_ICCV_ISDFR': '1ZPUlX18ugklzFXJ6XaeeomTdPjzf0qWu',\n",
        "    'Ghanem_2015_CVPR_RMFEF': '1QA5lYGHPzpVvEmX4eBtd50zEUxGfOECr',\n",
        "    'Dave_2012_ICPR_DHFOI': '1Gg7u3qegUtAehXiEzcx8exXAO5wTuQ8x',\n",
        "    'Bibi_2019_ICLR_DLASS': '1Am-YHOTURvPCGqYpQg917Kl0E0nG3VAG',\n",
        "    'Bibi_2017_ICCV_HOTFF': '1P-Dj07W8GyKzoAlXgOXymFaK2zxa_Dlx',\n",
        "    'Dubey_2015_ICCV_WMAOM': '1IqZ0ItUIn6HHUA1f8yN2CVa4F-IBUuvt',\n",
        "    'Dubey_2014_ACCV_ISMBP': '1IC0w58Qe2RlABr-e4wbF9-BPQb-5Wv-s',\n",
        "    'Buch_2017_BMVC_ESTAD': '18h2lT9ucA9SyD1CFmjHEuPrgMFReXT_X',\n",
        "    'Bibi_2018_CVPR_AEFPM': '183T-npqzO_7928bahmF8RW84LYj0OueC',\n",
        "    'Escorcia_2015_CVPR_OTRBV': '1nRtaHISp0aTJQYtYP1j4MmDWalXoxl85',\n",
        "    'Buch_2017_CVPR_SSTAP': '1pQM7xTz42DsKEHvMUN7aiacytMz79Oax',\n",
        "    'Escorcia_2016_ECCV_DDAPF': '1I36Gj1mbjMEp4XYbN3Cr3PZAxI6z52r-',\n",
        "    'Bibi_2015_ICCVW_MSKCF': '1-4vlaeL9hEA0dm3Obgpeen2VCx4LwJNO',\n",
        "    'Atmosukarto_2015_WACV_ARUDS': '1mkyOFvJPysX0N7BoWPG4kxeAo_7ahGzb',\n",
        "    'Alwassel_2018_ECCV_DEITA': '1jKlm47vzrExFbBLwRFvJYbkkyin2n9al',\n",
        "    'Bibi_2016_CVPR_PSTWA': '1P4qbtdtxtC5Px6A_q4kG8bbVMEkqsAbV',\n",
        "    'Bai_2018_CVPR_FTFIT': '1dQGQEtDzDvlB5ORRbKwC8wq9NrabhE6_',\n",
        "    'Atmosukarto_2013_CVPRW_AROOT': '1tV9N12QW0c4jXR6dEjRjyswR9kALIoSa',\n",
        "    'Bai_2018_ECCV_SSODV': '1C93ZhO-_0YsVS1lF3mbuo5FUcpbAcNvd',\n",
        "    'Bibi_2017_CVPR_FLLIT': '1l_nITGVloFPWnsjoxpTtO5eyA57J66sj',\n",
        "    'Atmosukarto_2012_ICPR_TFKRF': '1PZKjWK3rT4xDe3amIjZ2dsFYbETr96_i',\n",
        "    'Bibi_2016_ECCV_TRAFC': '1AjmUhLofEWC_6guQD_EBj6uzvE4wkxQY',\n",
        "    'Zhang_2018_CVPR_WAWTF': '1GCw5SWSnCuvVgAvjPMuHf1drUE15lhZS',\n",
        "    'Zhang_2018_PatternRecognition_WODVM': '1XssG8q0oa1uPtNMiRzu1Z50VkVyWcaUL',\n",
        "    'Zhang_2013_IJCV_RVTVS': '1QJgr-nEavVJeY6soN52upB-3vnrimH6a',\n",
        "    'Zhang_2015_Cybernetics_RVTVE': '1maUs6oPctHLD_-lIqvB9P5gmEhQTdw6B',\n",
        "    'Zhang_2014_IJCV_RVTVC': '1UXMh9DvAxqCTK8eyHaBx4fW3hr8KUUF4',\n",
        "    'Zhang_2015_CVPR_SST': '1FW0FVKUkkQlx-ivpew4YL1GcK1psfm-h',\n",
        "    'Zhang_2016_CVPR_IDOST': '1T9DGD2332msAJMeKuBNpZzlETlwTrkcO',\n",
        "    'Alwassel_2018_ECCV_ASSAI': '1gP6DKLWbfNsbEAFl1Uwh6LqRfL_tLMYi',\n",
        "    'Zhang_2018_CVPR_IIODN': '1W__LTrhSFyrhBZFXfJ16QTrbEHeWIjyy',\n",
        "    'Affara_2016_ECCV_LSAEF': '1ZtBaAMxmQM8THpR5zx3-aGpN-VgukOl-',\n",
        "    'Zhang_2012_CVPR_RVTVM': '1I8D9vk56o7smg9TvJT54GBI9xps0jOnQ',\n",
        "    'Yuan_2017_TPAMI_LASOM': '1KJqf7h-3ozOCehQIwYQpxsKCRRUcmrTa',\n",
        "    'Zhang_2012_ECCV_LSLFR': '1A1vVO2HEjD4KxqGoi7Cjs9UGeXourFhb',\n",
        "    'Zhang_2013_ICCV_LSCFI': '1lJQkRzUEXY1KC-vByo3XhdxRFYzOc5ZN',\n",
        "    'Zhang_2013_CVPRW_OTBOD': '1_DNTC-f-WwG8OlWzeXefmcDTLyHbiR_4',\n",
        "    'Yuan_2017_AAAI_AEPMF': '1L5_ErOayykJnzgykgMpduxmyVPDOkgDc',\n",
        "    'Yuan_2016_AAAI_APADM': '1SfnWLfzlvXar7zVXZ4MLSjCic7XD3kiQ',\n",
        "    'Yuan_2015_CVPR_LANMF': '1AtIKusQDMvKdfJ72YRD12FHqdUtxFNvl',\n",
        "    'Zhang_2012_ICASSP_RMTVC': '1YmS6W6XP058Kov768jY-f75UDPMfI9r7',\n",
        "    'Yuan_2017_CVPR_AMSMF': '12Kkw2ziI8X9tqFyfWUOv9rQ5lrCq4QXu',\n",
        "    'Xu_2019_CVPRW_MLIOD': '1jSSWrXKMmKUehy0kuHu7Q-4H9ddsh8pr',\n",
        "    'Yu_2018_ECCV_FSGBF': '1XwV6TkyQKBN9LVK4VCLghQMpXzABVb8Y',\n",
        "    'Xu_2019_CVPRW_SPRFR': '1r0R9P_65P8noVG76tX_z0T7R2obDj1PU',\n",
        "    'Wu_2018_TPAMI_LAAVF': '1f7TfNBIKWIT1yzXZ7fA3QSxp3c5hJD5M',\n",
        "    'Yu_2019_TPAMI_CWSMJ': '1pTK9miOIGi9DwHyEWGs6_6AvSKJkxyV3',\n",
        "    'Wu_2017_CVPR_DIA': '1Fq8E1UQwbNcwmZZSOtjf5lTzVwWAoUe7',\n",
        "    'Wu_2018_CVPR_TLHDA': '1wG2CWbzrKeVvxthe3oDNU7noEO87i-Up',\n",
        "    'Yuan_2013_NeuroComputing_BBGOF': '1ux336oOu3lZCy1if5mmUAU5nRMfdF0vt',\n",
        "    'Yuan_2012_NeuroComputing_LQSP': '1eg5fpAx3rSmsAs2aOwKqPWIJigXND88-',\n",
        "    'Wu_2018_IJCV_MLWML': '1Nnm0funn3RGpGy_dqEETqQdyKuyChZQ0',\n",
        "    'Shaheen_2017_EuroGraphics_SST': '1oZ2WBlvt9eaAD15kTyT5awfZJcz9-OFU',\n",
        "    'Muller_2019_CVPRW_LACFN': '1iYNnUNY52E3aOhyJqwS2UhE4R71KAv8g',\n",
        "    'Thabet_2014_ACCV_ACACO': '1dNY5uvr7g2oCuKoCUXlKU0mA15MXnucM',\n",
        "    'Shaheen_2015_EuroGraphics_SSAR': '1MLwSpr3xB7VdUAJa5U0NnPjvDmn7Kw4x',\n",
        "    'Wu_2015_ICCV_MMLWM': '1DU1lBeYZMkxhbQGm7yUvH7nCTQATQ0Tw',\n",
        "    'Shaheen_2017_ICCV_CCSCF': '1G9PKLW44AAI5-Mjp-vcHAlrFWUO-MxVq',\n",
        "    'Wonka_2015_EuroGraphics_TAFDU': '1tQlaoSz-PHcfk7z4WsjbgdymaGSWUJjy',\n",
        "    'Varadarajan_2013_BMVC_ATMAT': '1sIa-NFqaQ9iGfVQLeKK9AdUcQxvVhZfq',\n",
        "    'Protasiuk_2019_WACV_LCMCW': '1KPX77OUuhqP1FyfgRAaGAUiLOBR9JRHu',\n",
        "    'Wu_2016_AAAI_CSMFM': '1qXnMaFNfj8_L4ZfPT8fYzjF2zFNC1Oms',\n",
        "}\n",
        "theme = {\n",
        "    'Muller_2018_ECCV_TALDA': 2,\n",
        "    'Muller_2016_IROS_PATSF': 2,\n",
        "    'Muller_2018_IJCV_SAPSF': 2,\n",
        "    'Muller_2018_ECCVW_TUTRE': 2,\n",
        "    'Muller_2017_CVPR_CCFT': 2,\n",
        "    'Muller_2018_CORL_DPTVM': 2,\n",
        "    'Li_2019_ICCV_CGGAD': 3,\n",
        "    'Li_2019_RSS_OOIL': 2,\n",
        "    'Muller_2016_ECCV_ABASF': 2,\n",
        "    'Heilbron_2018_ECCV_WDIAN': 1,\n",
        "    'Li_2016_PatternRecognition_FAURU': 3,\n",
        "    'Lahoud_2019_ICCV_ISVMM': 2,\n",
        "    'Lahoud_2017_ICCV_ODIRI': 2,\n",
        "    'Heili_2014_ACCV_IHABP': 1,\n",
        "    'Huang_2019_AAAI_ANFFR': 3,\n",
        "    'Heilbron_2014_ACCV_CMASS': 1,\n",
        "    'Heilbron_2016_CVPR_FTAPF': 1,\n",
        "    'Heilbron_2015_CVPR_AALVB': 1,\n",
        "    'Heilbron_2017_CVPR_SSCCF': 1,\n",
        "    'Giancola_2018_CVPRW_SASDF': 1,\n",
        "    'Ghanem_2012_CVIU_MDS': 3,\n",
        "    'Ghanem_2015_EuroGraphics_DCNBC': 3,\n",
        "    'Giancola_2018_CVPRW_IOAOM': 2,\n",
        "    'Giancola_2019_CVPR_LSCFS': 2,\n",
        "    'Ghanem_2012_ICASSP_RVRAT': 1,\n",
        "    'Ghanem_2012_ICPR_CLFAS': 1,\n",
        "    'Hachama_2015_ICCV_ISDFR': 2,\n",
        "    'Ghanem_2015_CVPR_RMFEF': 2,\n",
        "    'Dave_2012_ICPR_DHFOI': 3,\n",
        "    'Bibi_2019_ICLR_DLASS': 3,\n",
        "    'Bibi_2017_ICCV_HOTFF': 3,\n",
        "    'Dubey_2015_ICCV_WMAOM': 3,\n",
        "    'Dubey_2014_ACCV_ISMBP': 3,\n",
        "    'Buch_2017_BMVC_ESTAD': 1,\n",
        "    'Bibi_2018_CVPR_AEFPM': 3,\n",
        "    'Escorcia_2015_CVPR_OTRBV': 1,\n",
        "    'Buch_2017_CVPR_SSTAP': 1,\n",
        "    'Escorcia_2016_ECCV_DDAPF': 1,\n",
        "    'Bibi_2015_ICCVW_MSKCF': 3,\n",
        "    'Atmosukarto_2015_WACV_ARUDS': 1,\n",
        "    'Alwassel_2018_ECCV_DEITA': 1,\n",
        "    'Bibi_2016_CVPR_PSTWA': 3,\n",
        "    'Bai_2018_CVPR_FTFIT': 2,\n",
        "    'Atmosukarto_2013_CVPRW_AROOT': 1,\n",
        "    'Bai_2018_ECCV_SSODV': 2,\n",
        "    'Bibi_2017_CVPR_FLLIT': 3,\n",
        "    'Atmosukarto_2012_ICPR_TFKRF': 1,\n",
        "    'Bibi_2016_ECCV_TRAFC': 2,\n",
        "    'Zhang_2018_CVPR_WAWTF': 2,\n",
        "    'Zhang_2018_PatternRecognition_WODVM': 2,\n",
        "    'Zhang_2013_IJCV_RVTVS': 2,\n",
        "    'Zhang_2015_Cybernetics_RVTVE': 2,\n",
        "    'Zhang_2014_IJCV_RVTVC': 2,\n",
        "    'Zhang_2015_CVPR_SST': 2,\n",
        "    'Zhang_2016_CVPR_IDOST': 2,\n",
        "    'Alwassel_2018_ECCV_ASSAI': 1,\n",
        "    'Zhang_2018_CVPR_IIODN': 2,\n",
        "    'Affara_2016_ECCV_LSAEF': 2,\n",
        "    'Zhang_2012_CVPR_RVTVM': 2,\n",
        "    'Yuan_2017_TPAMI_LASOM': 3,\n",
        "    'Zhang_2012_ECCV_LSLFR': 2,\n",
        "    'Zhang_2013_ICCV_LSCFI': 2,\n",
        "    'Zhang_2013_CVPRW_OTBOD': 2,\n",
        "    'Yuan_2017_AAAI_AEPMF': 3,\n",
        "    'Yuan_2016_AAAI_APADM': 3,\n",
        "    'Yuan_2015_CVPR_LANMF': 3,\n",
        "    'Zhang_2012_ICASSP_RMTVC': 2,\n",
        "    'Yuan_2017_CVPR_AMSMF': 2,\n",
        "    'Xu_2019_CVPRW_MLIOD': 3,\n",
        "    'Yu_2018_ECCV_FSGBF': 3,\n",
        "    'Xu_2019_CVPRW_SPRFR': 2,\n",
        "    'Wu_2018_TPAMI_LAAVF': 3,\n",
        "    'Yu_2019_TPAMI_CWSMJ': 3,\n",
        "    'Wu_2017_CVPR_DIA': 3,\n",
        "    'Wu_2018_CVPR_TLHDA': 3,\n",
        "    'Yuan_2013_NeuroComputing_BBGOF': 3,\n",
        "    'Yuan_2012_NeuroComputing_LQSP': 3,\n",
        "    'Wu_2018_IJCV_MLWML': 3,\n",
        "    'Shaheen_2017_EuroGraphics_SST': 3,\n",
        "    'Muller_2019_CVPRW_LACFN': 2,\n",
        "    'Thabet_2014_ACCV_ACACO': 2,\n",
        "    'Shaheen_2015_EuroGraphics_SSAR': 3,\n",
        "    'Wu_2015_ICCV_MMLWM': 3,\n",
        "    'Shaheen_2017_ICCV_CCSCF': 3,\n",
        "    'Wonka_2015_EuroGraphics_TAFDU': 3,\n",
        "    'Varadarajan_2013_BMVC_ATMAT': 1,\n",
        "    'Protasiuk_2019_WACV_LCMCW': 3,\n",
        "    'Wu_2016_AAAI_CSMFM': 3,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OznQcKs1d27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "references = set()\n",
        "for b in biblib:\n",
        "    references.add(b.reference)\n",
        "assert len(biblib) == len(references)\n",
        "biblib_json = {}\n",
        "for b in biblib:\n",
        "    links = dict(b.links)\n",
        "    for k in tuple(links):\n",
        "        if k == 'paper':\n",
        "            links[k] = paper[b.reference]\n",
        "        elif k == 'bibtex':\n",
        "            del links[k]\n",
        "        elif links[k][0] == '/':\n",
        "            links[k] = 'https://ivul.kaust.edu.sa' + links[k]\n",
        "    biblib_json[b.reference] = {\n",
        "        'title': b.title,\n",
        "        'authors': list(b.authors),\n",
        "        'venue': b.venue,\n",
        "        # 'full_venue': b.full_venue,\n",
        "        'theme': theme[b.reference],\n",
        "        'distinctions': list(b.distinctions),\n",
        "        # 'keywords': list(b.keywords),\n",
        "        'abstract': b.abstract,\n",
        "        'year': b.year,\n",
        "        'thumbnail': thumbnail[b.reference],\n",
        "        'links': links,\n",
        "        'co': b.coauthors,  # COMMENT THIS!!!!\n",
        "    }\n",
        "full_venue = {b.venue: b.full_venue for b in biblib}\n",
        "with open('biblib.js', 'w') as f:\n",
        "    f.write('const full_venue = ')\n",
        "    f.write(repr(full_venue))\n",
        "    f.write(';\\n')\n",
        "    f.write('const biblib = ')\n",
        "    f.write(repr(biblib_json))\n",
        "    f.write(';\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWTdhaGGCmKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTHORS = {\n",
        "    # current\n",
        "    'Bernard Ghanem': 'bernard',\n",
        "    'Ali Thabet': 'ali',\n",
        "    'Silvio Giancola': 'silvio',\n",
        "    'Adel Bibi': 'adel',\n",
        "    'Guohao Li': 'guohao',\n",
        "    'Hani Itani': 'hani',\n",
        "    'Humam Alwassel': 'humam',\n",
        "    'Jean Lahoud': 'jean',\n",
        "    'Jesus Zarzar': 'jesus',\n",
        "    'Modar Alfadly': 'modar',\n",
        "    'Mengmeng Xu': 'frost',\n",
        "\n",
        "    # alumnus\n",
        "    'Salman Alsubaihi': 'salman',\n",
        "    'Sara Shaheen': 'sara',\n",
        "    'Lama Affara': 'affara',\n",
        "    'Fabian Caba Heilbron': 'fabian',\n",
        "    'Victor Escorcia': 'victor',\n",
        "    'Baoyuan Wu': 'baoyuan',\n",
        "    'Ganzhao Yuan': 'ganzhao',\n",
        "    'Jia-Hong Huang': 'jiahong',\n",
        "    'Jian Zhang': 'jian',\n",
        "    'Yancheng Bai': 'yancheng',\n",
        "    'Yaicheng Bai': 'yancheng',\n",
        "    'Matthias Müller': 'matthias',\n",
        "\n",
        "    # visitors\n",
        "    'Yongqiang Zhang': 'yongqiang',\n",
        "    'Cuong Duc Dao': 'cuong',\n",
        "    'Gopal Sharma': 'gopal',\n",
        "    'Juan Carlos Niebles': 'juan',\n",
        "    'Rafał Protasiuk': 'rafal',\n",
        "    'Tarek Dghaily': 'tarek',\n",
        "    'Vincent Casser': 'vincent',\n",
        "    'Xin Yu': 'xin',\n",
        "\n",
        "    # collaborators\n",
        "    'Neil Smith': 'neil',\n",
        "    'Sally Sisi Qu': 'sally',\n",
        "    'Peter Wonka': 'peter',\n",
        "    'Dominik L Michels': 'dominik',\n",
        "    'Shyamal Buch': 'shyamal',\n",
        "    'Jens Schneider': 'jens',\n",
        "    'Aditya Khosla': 'aditya',\n",
        "    'Akshat Dave': 'akshat',\n",
        "    'Alexandre Heili': 'alexandre',\n",
        "    'Alexey Dosovitskiy': 'alexey',\n",
        "    'Alyn Rockwood': 'alyn',\n",
        "    'Basura Fernando': 'basura',\n",
        "    'Caigui Jiang': 'caigui',\n",
        "    'Changsheng Xu': 'changsheng',\n",
        "    'Chuanqi Shen': 'chuanqi',\n",
        "    'Daniel Asmar': 'daniel',\n",
        "    'Fan Jia': 'fan',\n",
        "    'Fatemeh Shiri': 'fatemeh',\n",
        "    'Fatih Porikli': 'fatih',\n",
        "    'Hailin Jin': 'hailin',\n",
        "    'Hongxun Yao': 'hongxun',\n",
        "    'Indriyati Atmosukarto': 'indriyati',\n",
        "    'Jagannadan Varadarajan': 'jagannadan',\n",
        "    'Jean-Marc Odobez': 'jeanmarc',\n",
        "    'Joon-Young Lee': 'joon',\n",
        "    'Joshua Peterson': 'joshua',\n",
        "    'Karthik Muthuswamy': 'karthik',\n",
        "    'Li Fei-Fei': 'li',\n",
        "    'Liangliang Nan': 'liangliang',\n",
        "    'Marc Farra': 'marcfarra',\n",
        "    'Marc Pollefeys': 'marc',\n",
        "    'Martin R Oswald': 'martin',\n",
        "    'Maya Kreidieh': 'maya',\n",
        "    'Ming-Hsuan Yang': 'ming',\n",
        "    'Mingli Ding': 'mingli',\n",
        "    'Mohammed Hachama': 'hachama',\n",
        "    'Mohieddine Amine': 'mohieddine',\n",
        "    'Narendra Ahuja': 'narendra',\n",
        "    'Peng Sun': 'peng',\n",
        "    'Qiang Ji': 'qiang',\n",
        "    'Rachit Dubey': 'rachit',\n",
        "    'René Ranftl': 'rene',\n",
        "    'Richard Hartley': 'richard',\n",
        "    'Shaunak Ahuja': 'shaunak',\n",
        "    'Shuicheng Yan': 'shuicheng',\n",
        "    'Si Liu': 'si',\n",
        "    'Siwei Lyu': 'siwei',\n",
        "    'Tianzhu Zhang': 'tianzhu',\n",
        "    'Vladlen Koltun': 'vladlen',\n",
        "    'Wayner Barrios': 'wayner',\n",
        "    'Wei Liu': 'wei',\n",
        "    'Wei-Shi Zheng': 'weishi',\n",
        "    'Weidong Chen': 'weidong',\n",
        "    'Yongping Zhao': 'yongping',\n",
        "    'Yongqiang Li': 'yongqiangli',\n",
        "    'Yuanhao Cao': 'yuanhao',\n",
        "    'Zhenjie Zhang': 'zhenjie',\n",
        "    'Zhifeng Hao': 'zhifeng',\n",
        "}\n",
        "VENUE_ORDER = ['TPAMI', 'IJCV', 'CVPR', 'CVPRW', 'ICCV', 'ICCVW',\n",
        "               'ECCV', 'ECCVW', 'ICLR', 'AAAI', 'ACCV', 'WACV',\n",
        "               'BMVC', 'ICPR', 'CVIU', 'ICASSP',\n",
        "               'PatternRecognition', 'NeuroComputing',\n",
        "               'EuroGraphics', 'Cybernetics', 'IROS', 'RSS', 'CORL']\n",
        "class Publication:\n",
        "    AUTHORS = {\n",
        "        'bernard': 'Bernard Ghanem',\n",
        "        'ali': 'Ali Thabet',\n",
        "        'silvio': 'Silvio Giancola',\n",
        "        'adel': 'Adel Bibi',\n",
        "        'guohao': 'Guohao Li',\n",
        "        'hani': 'Hani Itani',\n",
        "        'humam': 'Humam Alwassel',\n",
        "        'jean': 'Jean Lahoud',\n",
        "        'jesus': 'Jesus Zarzar',\n",
        "        'modar': 'Modar Alfadly',\n",
        "        'frost': 'Mengmeng Xu',\n",
        "        'salman': 'Salman Alsubaihi',\n",
        "        'sara': 'Sara Shaheen',\n",
        "        'affara': 'Lama Affara',\n",
        "        'fabian': 'Fabian Caba Heilbron',\n",
        "        'victor': 'Victor Escorcia',\n",
        "        'baoyuan': 'Baoyuan Wu',\n",
        "        'ganzhao': 'Ganzhao Yuan',\n",
        "        'jiahong': 'Jia-Hong Huang',\n",
        "        'jian': 'Jian Zhang',\n",
        "        'yancheng': 'Yancheng Bai',\n",
        "        'matthias': 'Matthias Müller',\n",
        "        'yongqiang': 'Yongqiang Zhang',\n",
        "        'cuong': 'Cuong Duc Dao',\n",
        "        'gopal': 'Gopal Sharma',\n",
        "        'juan': 'Juan Carlos Niebles',\n",
        "        'rafal': 'Rafał Protasiuk',\n",
        "        'tarek': 'Tarek Dghaily',\n",
        "        'vincent': 'Vincent Casser',\n",
        "        'xin': 'Xin Yu',\n",
        "        'neil': 'Neil Smith',\n",
        "        'sally': 'Sally Sisi Qu',\n",
        "        'peter': 'Peter Wonka',\n",
        "        'dominik': 'Dominik L Michels',\n",
        "        'shyamal': 'Shyamal Buch',\n",
        "        'jens': 'Jens Schneider',\n",
        "        'aditya': 'Aditya Khosla',\n",
        "        'akshat': 'Akshat Dave',\n",
        "        'alexandre': 'Alexandre Heili',\n",
        "        'alexey': 'Alexey Dosovitskiy',\n",
        "        'alyn': 'Alyn Rockwood',\n",
        "        'basura': 'Basura Fernando',\n",
        "        'caigui': 'Caigui Jiang',\n",
        "        'changsheng': 'Changsheng Xu',\n",
        "        'chuanqi': 'Chuanqi Shen',\n",
        "        'daniel': 'Daniel Asmar',\n",
        "        'fan': 'Fan Jia',\n",
        "        'fatemeh': 'Fatemeh Shiri',\n",
        "        'fatih': 'Fatih Porikli',\n",
        "        'hailin': 'Hailin Jin',\n",
        "        'hongxun': 'Hongxun Yao',\n",
        "        'indriyati': 'Indriyati Atmosukarto',\n",
        "        'jagannadan': 'Jagannadan Varadarajan',\n",
        "        'jeanmarc': 'Jean-Marc Odobez',\n",
        "        'joon': 'Joon-Young Lee',\n",
        "        'joshua': 'Joshua Peterson',\n",
        "        'karthik': 'Karthik Muthuswamy',\n",
        "        'li': 'Li Fei-Fei',\n",
        "        'liangliang': 'Liangliang Nan',\n",
        "        'marcfarra': 'Marc Farra',\n",
        "        'marc': 'Marc Pollefeys',\n",
        "        'martin': 'Martin R Oswald',\n",
        "        'maya': 'Maya Kreidieh',\n",
        "        'ming': 'Ming-Hsuan Yang',\n",
        "        'mingli': 'Mingli Ding',\n",
        "        'hachama': 'Mohammed Hachama',\n",
        "        'mohieddine': 'Mohieddine Amine',\n",
        "        'narendra': 'Narendra Ahuja',\n",
        "        'peng': 'Peng Sun',\n",
        "        'qiang': 'Qiang Ji',\n",
        "        'rachit': 'Rachit Dubey',\n",
        "        'rene': 'René Ranftl',\n",
        "        'richard': 'Richard Hartley',\n",
        "        'shaunak': 'Shaunak Ahuja',\n",
        "        'shuicheng': 'Shuicheng Yan',\n",
        "        'si': 'Si Liu',\n",
        "        'siwei': 'Siwei Lyu',\n",
        "        'tianzhu': 'Tianzhu Zhang',\n",
        "        'vladlen': 'Vladlen Koltun',\n",
        "        'wayner': 'Wayner Barrios',\n",
        "        'wei': 'Wei Liu',\n",
        "        'weishi': 'Wei-Shi Zheng',\n",
        "        'weidong': 'Weidong Chen',\n",
        "        'yongping': 'Yongping Zhao',\n",
        "        'yongqiangli': 'Yongqiang Li',\n",
        "        'yuanhao': 'Yuanhao Cao',\n",
        "        'zhenjie': 'Zhenjie Zhang',\n",
        "        'zhifeng': 'Zhifeng Hao',\n",
        "    }\n",
        "    VENUES = {\n",
        "        'TPAMI':\n",
        "            'IEEE Transactions on Pattern Analysis and Machine Intelligence',\n",
        "        'IJCV':\n",
        "            'International Journal of Computer Vision',\n",
        "        'CVPR':\n",
        "            'IEEE Conference on Computer Vision and Pattern Recognition',\n",
        "        'CVPRW':\n",
        "            'IEEE Conference on Computer Vision and Pattern Recognition Workshops',\n",
        "        'ICCV':\n",
        "            'IEEE International Conference on Computer Vision',\n",
        "        'ICCVW':\n",
        "            'IEEE International Conference on Computer Vision Workshops',\n",
        "        'ECCV':\n",
        "            'IEEE European Conference on Computer Vision',\n",
        "        'ECCVW':\n",
        "            'IEEE European Conference on Computer Vision Workshops',\n",
        "        'ICLR':\n",
        "            'International Conference on Learning Representations',\n",
        "        'AAAI':\n",
        "            'Association for the Advancement of Artificial Intelligence',\n",
        "        'ACCV':\n",
        "            'Asian Conference on Computer Vision',\n",
        "        'WACV':\n",
        "            'IEEE Winter Conference on Applications of Computer Vision',\n",
        "        'BMVC':\n",
        "            'British Machine Vision Conference',\n",
        "        'ICPR':\n",
        "            'International Conference on Pattern Recognition',\n",
        "        'CVIU':\n",
        "            'Computer Vision and Image Understanding',\n",
        "        'ICASSP':\n",
        "            'IEEE International Conference on Acoustics, Speech and Signal Processing',\n",
        "        'PatternRecognition':\n",
        "            'Pattern Recognition Journal',\n",
        "        'NeuroComputing':\n",
        "            'Neurocomputing Journal',\n",
        "        'EuroGraphics':\n",
        "            'EuroGraphics Computer Graphics Forum',\n",
        "        'Cybernetics':\n",
        "            'IEEE Transactions on Cybernetics',\n",
        "        'IROS':\n",
        "            'International Conference on Intelligent Robots and Systems',\n",
        "        'RSS':\n",
        "            'Robotics Science and Systems',\n",
        "        'CORL':\n",
        "            'Conference on Robot Learning',\n",
        "    }\n",
        "    COLLABORATORS = ('*', '+', '×', '▪', '▴', '▾')\n",
        "    DISTINCTIONS = ('Short Paper', 'Spotlight', 'Oral', 'Best Paper Award')\n",
        "    LINKS = ('Code', 'Data', 'Video', 'Poster', 'Slides', 'More', 'Website')\n",
        "\n",
        "    def __init__(self, key, title, authors, distinctions, paper, links,\n",
        "                 abstract, thumbnail):\n",
        "        self.theme, self.year, self.venue = key\n",
        "        assert self.venue in self.VENUES\n",
        "        self.title = title\n",
        "        self.abstract = abstract\n",
        "        self.authors = tuple(\n",
        "            (a,) if isinstance(a, str) else tuple(a) for a in authors)\n",
        "        assert all(\n",
        "            a in self.AUTHORS for t in self.authors for a in t), self.authors\n",
        "        self.distinctions = tuple(distinctions)\n",
        "        assert all(d in self.DISTINCTIONS\n",
        "                   for d in self.distinctions), self.distinctions\n",
        "        self.links = links\n",
        "        assert all(l in self.LINKS for l in self.links.keys()), list(\n",
        "            self.links.keys())\n",
        "        self.paper = paper\n",
        "        self.thumbnail = thumbnail"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEB4wqXJl1p7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for b in sorted(biblib_json.values(), key=lambda b: (\n",
        "        -b['year'], VENUE_ORDER.index(b['venue']), b['authors'][0])):\n",
        "    authors = tuple(AUTHORS[a] for a in b['authors'])\n",
        "    coauthors = sum(b['co'])  # uncomment in biblib_json\n",
        "    if coauthors:\n",
        "        start = b['co'].index(True)\n",
        "        end = start + coauthors\n",
        "        authors = (*authors[:start], tuple(authors[start:end]), *authors[end:])\n",
        "    print('Publication(\\n    ', end='')\n",
        "    print(\n",
        "        (b['theme'], b['year'], b['venue']),\n",
        "        repr(b['title']),\n",
        "        authors,\n",
        "        tuple(b['distinctions']),\n",
        "        repr(b['links']['paper']),\n",
        "        '{}' if len(b['links']) <= 1 else str(\n",
        "            {k.title() if k != 'supplementary' else 'More':\n",
        "            v for k, v in b['links'].items() if k != 'paper'})[:-1]+',}',\n",
        "        repr(b['abstract']),\n",
        "        repr(b['thumbnail']),\n",
        "        sep=',\\n    ', end=',\\n),\\n'\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}